{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "source": [
        "!pip install yt-dlp\n",
        "import yt_dlp  # Import yt-dlp instead of youtube-dl\n",
        "\n",
        "ydl_opts = {\n",
        "    'format': 'best',  # Download the best quality available, regardless of signature\n",
        "    'outtmpl': 'audio.%(ext)s',\n",
        "    'extractaudio': True,\n",
        "    'audioformat': 'mp3'\n",
        "}\n",
        "\n",
        "with yt_dlp.YoutubeDL(ydl_opts) as ydl:  # Use yt_dlp.YoutubeDL\n",
        "    ydl.download(['YOUR_YOUTUBE_URL'])"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "XhaoU23BQSxN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "!sudo apt-get install ffmpeg  # If you're on a Linux system using apt\n",
        "!ffmpeg -i audio.mp4 -vn -acodec libmp3lame -ab 192k audio.mp3\n",
        "!pip install openai\n",
        "\n",
        "import os\n",
        "\n",
        "# Set the API key as an environment variable\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"YOUR_OPENAI_KEY\"\n",
        "\n",
        "import openai\n",
        "\n",
        "# Create an OpenAI client (no need to pass api_key here)\n",
        "client = openai.OpenAI()\n",
        "\n",
        "with open(\"audio.mp3\", \"rb\") as audio_file:\n",
        "    # Use the new transcription method\n",
        "    transcript = client.audio.transcriptions.create(\n",
        "        model=\"whisper-1\",\n",
        "        file=audio_file\n",
        "    )\n",
        "\n",
        "print(transcript.text) # Access the transcribed text using .text"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "eMPXZg8BRgZ2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
